name: Data scraping and deployment

on:
  push:
    branches: [master]
  schedule:
    - cron: "35 10 * * *"
    - cron: "50 10 * * *"

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Setup Node
        uses: actions/setup-node@v1
        with:
          node-version: "12.x"

      - name: Cache dependencies
        uses: actions/cache@v1
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      # Data scraping
      - name: Set up Python 3.8
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Data scraping
        run: |
          cd ./scraping
          python -m pip install --upgrade pip
          pip install flake8 pytest
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python twitter.py ${{secrets.CONSUMER_KEY}} ${{secrets.CONSUMER_SECRET}} ${{secrets.ACCESS_KEY}} ${{secrets.ACCESS_SECRET}} > ../src/data/statsData.json
          cat ../src/data/statsData.json

      - name: Update lastUpdateDate.json
        run: |
          sudo apt-get install jq
          cat ./src/data/lastUpdateDate.json
          jq '.lastCases = $today' --arg today $(eval date +'%d.%m.%Y') src/data/lastUpdateDate.json > temp.json
          cat temp.json > src/data/lastUpdateDate.json
          rm temp.json

      - run: npm ci
      - run: npm run build

      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@3.7.1
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH: gh-pages # The branch the action should deploy to.
          FOLDER: build # The folder the action should deploy.
          CLEAN: true # Automatically remove deleted files from the deploy branch

