name: Data scraping and deployment

on:
  push:
    branches: [master]
  pull_request:
    branches: [master]
  schedule:
    - cron: "0 11 * * *"

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Setup Node
        uses: actions/setup-node@v1
        with:
          node-version: "12.x"

      - name: Cache dependencies
        uses: actions/cache@v1
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      # Data scraping
      - name: Set up Python 3.8
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Data scraping
        run: |
          cd ./scraping
          python -m pip install --upgrade pip
          pip install flake8 pytest
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python twitter.py > ../src/data/statsData.json

      - name: Update lastUpdateDate.json
        run: |
          node -p "JSON.stringify({...require('./src/data/lastUpdateDate.json'), lastCases: `${new Date().getDay()+1}.${new Date().getMonth()+1}.${new Date().getFullYear()}`}, null, 2)" > ./src/data/lastUpdateDate.json

      - run: npm ci
      - run: npm run build

      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@3.7.1
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH: gh-pages # The branch the action should deploy to.
          FOLDER: build # The folder the action should deploy.
          CLEAN: true # Automatically remove deleted files from the deploy branch

